{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22979898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wsgiref import headers\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# from csv import writer\n",
    "from csv import DictWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef645f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Special:AllPages?from=&to=&namespace=0'\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f6403bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "links = soup.find_all(\"a\", { \"class\" : \"mw-redirect\" })\n",
    "lines = []\n",
    "for link in links:\n",
    "    newLine = '\"' + link['href'] + '\",\"' +  link.text + '\"'\n",
    "    lines.append(newLine)\n",
    "\n",
    "nextPageLinks = soup.find_all(\"a\", { \"title\" : \"Special:AllPages\" })\n",
    "if (len(nextPageLinks) <= 0):\n",
    "    print(\"Error finding next page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "715d09f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0: https://en.wikipedia.org/wiki/Special:AllPages?from=&to=&namespace=0\n",
      "\tWill save 317 lines\n",
      "\tSaved! 317 lines saved already\n",
      "Step: 1: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22All-in%22+wrestling\n",
      "\tWill save 308 lines\n",
      "\tSaved! 625 lines saved already\n",
      "Step: 2: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22Comes+With+Music%22\n",
      "\tWill save 323 lines\n",
      "\tSaved! 948 lines saved already\n",
      "Step: 3: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22GaI%22\n",
      "\tWill save 308 lines\n",
      "\tSaved! 1256 lines saved already\n",
      "Step: 4: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22Jig+Dog%22+Ramage+Carrier+and+Carrier+Air+Wing+Operational+Excellence+Award\n",
      "\tWill save 328 lines\n",
      "\tSaved! 1584 lines saved already\n",
      "Step: 5: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22Miz+Maze%22\n",
      "\tWill save 326 lines\n",
      "\tSaved! 1910 lines saved already\n",
      "Step: 6: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22Pretty+Wild%22+TV+Show\n",
      "\tWill save 327 lines\n",
      "\tSaved! 2237 lines saved already\n",
      "Step: 7: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22Still+Life%22+at+the+Penguin+Cafe\n",
      "\tWill save 333 lines\n",
      "\tSaved! 2570 lines saved already\n",
      "Step: 8: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22Tokie%22+Slaughter\n",
      "\tWill save 305 lines\n",
      "\tSaved! 2875 lines saved already\n",
      "Step: 9: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%22blood+spinning%22\n",
      "\tWill save 327 lines\n",
      "\tSaved! 3202 lines saved already\n",
      "Step: 10: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%241+Coin\n",
      "\tWill save 312 lines\n",
      "\tSaved! 3514 lines saved already\n",
      "Step: 11: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%25u0192\n",
      "\tWill save 281 lines\n",
      "\tSaved! 3795 lines saved already\n",
      "Step: 12: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%2781-%2785\n",
      "\tWill save 312 lines\n",
      "\tSaved! 4107 lines saved already\n",
      "Step: 13: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%27Abdullah+ibn+Umm+Maktum\n",
      "\tWill save 314 lines\n",
      "\tSaved! 4421 lines saved already\n",
      "Step: 14: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%27Amidah\n",
      "\tWill save 306 lines\n",
      "\tSaved! 4727 lines saved already\n",
      "Step: 15: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%27Curly%27+Mack\n",
      "\tWill save 305 lines\n",
      "\tSaved! 5032 lines saved already\n",
      "Step: 16: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%27Mamoroallo+Tjoka\n",
      "\tWill save 264 lines\n",
      "\tSaved! 5296 lines saved already\n",
      "Step: 17: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%27Sweet+Joe%27+Russell\n",
      "\tWill save 267 lines\n",
      "\tSaved! 5563 lines saved already\n",
      "Step: 18: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%27Usfurid\n",
      "\tWill save 301 lines\n",
      "\tSaved! 5864 lines saved already\n",
      "Step: 19: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%27t+Gulden+Zeepaert+%28ship%2C+1626%29\n",
      "\tWill save 265 lines\n",
      "\tSaved! 6129 lines saved already\n",
      "Step: 20: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%28%2B%29-syringaresinol\n",
      "\tWill save 319 lines\n",
      "\tSaved! 6448 lines saved already\n",
      "Step: 21: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%28101180%29+1998+SH9\n",
      "\tWill save 337 lines\n",
      "\tSaved! 6785 lines saved already\n",
      "Step: 22: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%2811857%29+1988+RK9\n",
      "\tWill save 330 lines\n",
      "\tSaved! 7115 lines saved already\n",
      "Step: 23: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%2813514%29+1990+MR\n",
      "\tWill save 329 lines\n",
      "\tSaved! 7444 lines saved already\n",
      "Step: 24: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%28149349%29+2002+VA131\n",
      "\tWill save 317 lines\n",
      "\tSaved! 7761 lines saved already\n",
      "Step: 25: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%2816539%29+1991+PY12\n",
      "\tWill save 333 lines\n",
      "\tSaved! 8094 lines saved already\n",
      "Step: 26: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%2818528%29+1996+VX30\n",
      "\tWill save 324 lines\n",
      "\tSaved! 8418 lines saved already\n",
      "Step: 27: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%282101%29+Adonis\n",
      "\tWill save 334 lines\n",
      "\tSaved! 8752 lines saved already\n",
      "Step: 28: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%28243%29+Ida\n",
      "\tWill save 333 lines\n",
      "\tSaved! 9085 lines saved already\n",
      "Step: 29: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%2827850%29+1994+UD2\n",
      "\tWill save 338 lines\n",
      "\tSaved! 9423 lines saved already\n",
      "Step: 30: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%282Z%2C4E%29-2-hydroxy-6-oxona-2%2C4-dienedioate+succinylhydrolase\n",
      "\tWill save 318 lines\n",
      "\tSaved! 9741 lines saved already\n",
      "Step: 31: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%28332%29+Siri\n",
      "\tWill save 324 lines\n",
      "\tSaved! 10065 lines saved already\n",
      "Step: 32: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%28389305%29+2009+RY49\n",
      "\tWill save 320 lines\n",
      "\tSaved! 10385 lines saved already\n",
      "Step: 33: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%2843771%29+1988+TJ\n",
      "\tWill save 319 lines\n",
      "\tSaved! 10704 lines saved already\n",
      "Step: 34: https://en.wikipedia.org/w/index.php?title=Special:AllPages&from=%2848455%29+1991+PK13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStep: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(step) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m url)\n\u001b[0;32m     12\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m---> 14\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m links \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmw-redirect\u001b[39m\u001b[38;5;124m\"\u001b[39m })\n\u001b[0;32m     17\u001b[0m lines \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m    397\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTMLParseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\html\\parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\html\\parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[1;34m(self, end)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, i):\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m starttagopen\u001b[38;5;241m.\u001b[39mmatch(rawdata, i): \u001b[38;5;66;03m# < + letter\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m    172\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\html\\parser.py:344\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_cdata_mode(tag)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\builder\\_htmlparser.py:154\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[1;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m#print(\"START\", name)\u001b[39;00m\n\u001b[0;32m    153\u001b[0m sourceline, sourcepos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetpos()\n\u001b[1;32m--> 154\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msourceline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourceline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43msourcepos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourcepos\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mand\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mis_empty_element \u001b[38;5;129;01mand\u001b[39;00m handle_empty_element:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# events for tags of this name.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:721\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[1;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    718\u001b[0m          \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39msearch_tag(name, attrs))):\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_classes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTag\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrentTag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_most_recent_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43msourceline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourceline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msourcepos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourcepos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespaces\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tag\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py:1256\u001b[0m, in \u001b[0;36mTag.__init__\u001b[1;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml, sourceline, sourcepos, can_be_empty_element, cdata_list_attributes, preserve_whitespace_tags, interesting_string_types, namespaces)\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknown_xml \u001b[38;5;241m=\u001b[39m is_xml\n\u001b[1;32m-> 1256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;241m=\u001b[39m attrs\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup(parent, previous)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Special:AllPages?from=&to=&namespace=0'\n",
    "count_total = 0\n",
    "step = 0\n",
    "field_names = ['LINK', 'TITLE']\n",
    "\n",
    "with open('../Data/wiki.csv', 'w', encoding=\"utf-8\") as f_object:\n",
    "    f_object.write('LINE, TITLE\\n')\n",
    "\n",
    "while True:\n",
    "    print('Step: ' + str(step) + ': ' + url)\n",
    "    \n",
    "    res = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    links = soup.find_all(\"a\", { \"class\" : \"mw-redirect\" })\n",
    "    lines = []\n",
    "    for link in links:\n",
    "        newLine = '\"' + link['href'].replace(',', '').replace('\"', '') + '\", \"' + link.text + '\"'\n",
    "        lines.append(newLine)\n",
    "        \n",
    "    print('\\tWill save ' + str(len(lines)) + ' lines')\n",
    "    count_total += len(lines)\n",
    "\n",
    "    nextPageLinks = soup.find_all(\"a\", { \"title\" : \"Special:AllPages\" })\n",
    "    if (len(nextPageLinks) <= 0):\n",
    "        print(\"Error finding next page\")\n",
    "        break\n",
    "    url = 'https://en.wikipedia.org' + nextPageLinks[len(nextPageLinks) - 1]['href']\n",
    "    \n",
    "    with open('../Data/wiki.csv', 'a', encoding=\"utf-8\") as f_object:\n",
    "        for line in lines:\n",
    "            f_object.write(line + '\\n')\n",
    "        \n",
    "    print('\\tSaved! ' + str(count_total) + ' lines saved already')\n",
    "        \n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2430657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
